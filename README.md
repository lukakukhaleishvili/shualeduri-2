# shualeduri-2
კოიდ იხილეთ შუალედური_2.ipunb -ში

პროექტის მიზანია:
შექმნა ავტოენკოდერი, რომელსაც შეუძლია CIFAR-10 სურათების გაწვრთნა ისე, რომ მან შეძლოს:

კომპრესია (დაკომპაქტება),

რეკონსტრუქცია (აღდგენა) მინიმალური ხარვეზით,

გამოსახულებების გენერაცია ან აღდგენა დაზიანების შემდეგ.


1. მონაცემთა მომზადება

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])


- CIFAR-10 სურათები გადავაქციეთ Tensor-ად, რათა მოდელმა შეძლოს მათზე მუშაობა.
- გამოვიყენეთ ნორმალიზაცია [-1, 1] დიაპაზონში, რაც აუცილებელია Tanh() აქტივაციის სწორად მუშაობისთვის.

ნეირონულ ქსელს ვიყენებთ, რადგან ნეირონული ქსელები უკეთ სწავლობენ, როცა მონაცემები სტანდარტულად გადანაწილებულია (საშუალო ~0).ასევე ჩვენს შემთხვევაში, Tanh() ფინალურ ფენაში მუშაობს [-1, 1] დიაპაზონზე, ამიტომ ეს ნაბიჯი კრიტიკულია.


2. ავტოენკოდერის არქიტექტურა
ენდკოდერი:
Conv2d(3, 16) → 32
Conv2d(16, 32) → 16
Conv2d(32, 64) → 8
Conv2d(64, 128) → 4
დეკოდერი:
ConvTranspose2d(128, 64) → 8
ConvTranspose2d(64, 32) → 16
ConvTranspose2d(32, 16) → 32
ConvTranspose2d(16, 3) → 32


ჩვენმა მოდელმა ჯერ Encoder-ის დახმარებით შეამცირა სურათის ზომა და იგი გარდაქმნა „შესწავლულ მახასიათებლებად“. შემდეგ Decoder-მა აღადგინა ეს მახასიათებლები თავდაპირველი ზომის (32x32x3) სურათად. შუალედურ ფენებში გამოვიყენეთ ReLU აქტივაცია, ხოლო საბოლოო ფენაში Tanh ფუნქცია, რაც მონაცემთა დიაპაზონს უკეთესად შეესაბამება. Convolutional ფენების გამოყენება განპირობებულია მათი უნარით, უკეთ შეინარჩუნონ სურათების სივრცობრივი სტრუქტურა. ამასთან, stride=2 პარამეტრის გამოყენებით ყოველი ფენის შემდეგ ზომა ორჯერ მცირდება, რაც ეფექტურად ახდენს ინფორმაციის კომპრესიას.


3. გაწვრთნის ციკლი
num_epochs = 50
batch_size = 64
loss = MSELoss
optimizer = Adam


ჩვენ გამოვიყენეთ MSE Loss, რომელიც საშუალო კვადრატული შეცდომით ზომავს ორ სურათს შორის განსხვავებას. ოპტიმიზაციისთვის ავირჩიეთ Adam, რადგან ის უზრუნველყოფს სწრაფ და სტაბილურ კონვერგირებას. მოდელის სწავლისთვის 50 ეპოქა საკმარისი აღმოჩნდა, რათა ავტოენკოდერმა შეძლოს სურათების სტრუქტურის კარგად ათვისება. MSE-ის გამოყენება აუცილებელია იმისთვის, რომ რეკონსტრუქცია მაქსიმალურად მიახლოებული იყოს ორიგინალურ სურათთან პიქსელების დონეზე.


4. სურათების ჩენება და unnormalize

def unnormalize(img):
    return img * 0.5 + 0.5

სურათები ნორმალიზებულია დიაპაზონში [-1, 1], თუმცა ჩვენებისთვის მათი ჩვენება საჭიროა დიაპაზონში [0, 1]. ამიტომ, ფუნქცია unnormalize აბრუნებს გამოსახულებას თავდაპირველ, საწყის მდგომარეობაში, რომ ნახვა იყოს სწორად შესრულებული.


5. რეკონსტრუქციის ჩვენება

imshow(torchvision.utils.make_grid(sample_images.cpu()))
imshow(torchvision.utils.make_grid(reconstructed.cpu().detach()))

ჩვენ შევადარეთ ორიგინალი სურათები მოდელის მიერ აღდგენილ სურათებს, რაც საშუალებას გვაძლევს გავიგოთ, რამდენად ეფექტურად შეუძლია მოდელს ინფორმაცია შეინარჩუნოს და აღადგინოს. ეს შედარება გვიჩვენებს მოდელის შესრულების ხარისხს რეკონსტრუქციის პროცესში.


ავტოენკოდერი სწავლობს სურათის შიდა სტრუქტურას და ცდილობს მას შეჯამებული, მცირე ზომის წარმოდგენაში (latent space) გადაიტანოს. ამ პროცესში ის ითვისებს, როგორი უნდა იყოს „კარგი სურათი“, რათა შეძლოს მისი სწორი რეკონსტრუქცია. ავტოენკოდერი არ არის შექმნილი კლასიფიკაციისთვის — მისი მიზანი მხოლოდ სურათის აღდგენა და წარმოსახვაა.


ბოლოში შევადარეთ ორიგინალ და რეკონსტრუირებულ სურათებს და დავთვალეთ საშუალო განსხვავება პიქსელებზე პროცენტულად.


